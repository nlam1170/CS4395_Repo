{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad5cc3a-8624-468e-a433-43ab798b8608",
   "metadata": {},
   "source": [
    "import the NLTK library and the needed helper functions, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "beb7b5c3-783b-4aa6-90b8-29f079706986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import *\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42a14b-90a2-4e58-99d2-29b82b173233",
   "metadata": {},
   "source": [
    "1. NLTK text objects are already pre-tokenized\n",
    "2. NLTK text objects come with some nice built-in-functions similar to python std such as count() and len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89adc46-c038-4ec6-865f-b7aa7187656c",
   "metadata": {},
   "source": [
    "Display the first 20 tokens of text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6a267fe-29ab-4398-a52d-e48e14c42dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be33813-b750-4b92-84fa-647b5bffe2f4",
   "metadata": {},
   "source": [
    "Display the first 5 lines with concordance of \"sea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "18eb67ac-a02c-4d85-bc4a-426ce2ba47a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 455 matches:\n",
      " shall slay the dragon that is in the sea .\" -- ISAIAH \" And what thing soever \n",
      " S PLUTARCH ' S MORALS . \" The Indian Sea breedeth the most and the biggest fis\n",
      "cely had we proceeded two days on the sea , when about sunrise a great many Wha\n",
      "many Whales and other monsters of the sea , appeared . Among the former , one w\n",
      " waves on all sides , and beating the sea before him into a foam .\" -- TOOKE ' \n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"sea\", lines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19362ce4-4d8e-4ab4-adeb-9abb642bf228",
   "metadata": {},
   "source": [
    "Counts the instance of \"a\" in text1 using the NLTK count method and the python std count method found in python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b890b521-8392-4bb3-a4c7-d3917244af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4569\n",
      "4569\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The count method in the NLTK returns the occurences of a given string from any NLTK text object.\n",
    "This is the same as the python API method provided in the std library. We can see this by converting the Text Object into a normal python list and then using the count method.\n",
    "The result ends up being the same with both methods\n",
    "'''\n",
    "print(text1.count(\"a\"))\n",
    "print((list(text1)).count(\"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5365daa-a402-49a2-bc5f-4cde2dc4e5ba",
   "metadata": {},
   "source": [
    "tokenizes the raw_text into words, and then prints the first 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "037b97bc-561b-4c3e-a8ec-3ffbbbfd8179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Far', 'over', 'the', 'Misty', 'Mountains', 'cold', '.', 'To', 'dungeons', 'deep']\n"
     ]
    }
   ],
   "source": [
    "#The raw text is from the Misty Mountain song in Lord of The Rings\n",
    "raw_text = \"Far over the Misty Mountains cold. \\\n",
    "To dungeons deep and caverns old. \\\n",
    "We must away, ere break of day. \\\n",
    "To find our long forgotten gold. \\\n",
    "The pines were roaring on the height. \\\n",
    "The winds were moaning in the night. \\\n",
    "The fire was red, it flaming spread. \\\n",
    "The trees like torches blazed with light. \\\n",
    "The wind was on the withered heath. \\\n",
    "But in the forest stirred no leaf. \\\n",
    "There shadows lay be night or day. \\\n",
    "And dark things silent crept beneath. \\\n",
    "\"\n",
    "tokens = word_tokenize(raw_text)\n",
    "print(tokens[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06439bb0-fcee-4dd6-973f-4191824727e8",
   "metadata": {},
   "source": [
    "tokenizes the raw_text into sentences, then displays all the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d5578836-6803-4d59-becd-5affa6b29806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Far over the Misty Mountains cold.',\n",
       " 'To dungeons deep and caverns old.',\n",
       " 'We must away, ere break of day.',\n",
       " 'To find our long forgotten gold.',\n",
       " 'The pines were roaring on the height.',\n",
       " 'The winds were moaning in the night.',\n",
       " 'The fire was red, it flaming spread.',\n",
       " 'The trees like torches blazed with light.',\n",
       " 'The wind was on the withered heath.',\n",
       " 'But in the forest stirred no leaf.',\n",
       " 'There shadows lay be night or day.',\n",
       " 'And dark things silent crept beneath.']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens = sent_tokenize(raw_text)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b49d6b0-563c-4956-a870-ca9a9287bfa8",
   "metadata": {},
   "source": [
    "creates a stem object using PorterStemmer() then stems each of the tokens using lis comprehension. The stemmed tokens are then printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dacb1ff1-14d4-477b-b7bc-6bfb476d2077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['far', 'over', 'the', 'misti', 'mountain', 'cold', '.', 'to', 'dungeon', 'deep', 'and', 'cavern', 'old', '.', 'we', 'must', 'away', ',', 'ere', 'break', 'of', 'day', '.', 'to', 'find', 'our', 'long', 'forgotten', 'gold', '.', 'the', 'pine', 'were', 'roar', 'on', 'the', 'height', '.', 'the', 'wind', 'were', 'moan', 'in', 'the', 'night', '.', 'the', 'fire', 'wa', 'red', ',', 'it', 'flame', 'spread', '.', 'the', 'tree', 'like', 'torch', 'blaze', 'with', 'light', '.', 'the', 'wind', 'wa', 'on', 'the', 'wither', 'heath', '.', 'but', 'in', 'the', 'forest', 'stir', 'no', 'leaf', '.', 'there', 'shadow', 'lay', 'be', 'night', 'or', 'day', '.', 'and', 'dark', 'thing', 'silent', 'crept', 'beneath', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(t) for t in tokens]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfdc3c-6873-4853-8d26-046a097c9a29",
   "metadata": {},
   "source": [
    "1. misti-Misty\n",
    "2. mountain-Mountains\n",
    "3. flame-flaming\n",
    "4. wither-withered\n",
    "5. stir-stirred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14333f-dbb7-4292-badc-3f794f840fbb",
   "metadata": {},
   "source": [
    "creates a word lemmatize object using WordNetLemmatier(), then we lemmatize each of the tokens from the text using list comprehension. Then the lemmatized tokens are printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce9533aa-f1f9-4669-8659-88f19370fd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Far', 'over', 'the', 'Misty', 'Mountains', 'cold', '.', 'To', 'dungeon', 'deep', 'and', 'cavern', 'old', '.', 'We', 'must', 'away', ',', 'ere', 'break', 'of', 'day', '.', 'To', 'find', 'our', 'long', 'forgotten', 'gold', '.', 'The', 'pine', 'were', 'roaring', 'on', 'the', 'height', '.', 'The', 'wind', 'were', 'moaning', 'in', 'the', 'night', '.', 'The', 'fire', 'wa', 'red', ',', 'it', 'flaming', 'spread', '.', 'The', 'tree', 'like', 'torch', 'blazed', 'with', 'light', '.', 'The', 'wind', 'wa', 'on', 'the', 'withered', 'heath', '.', 'But', 'in', 'the', 'forest', 'stirred', 'no', 'leaf', '.', 'There', 'shadow', 'lay', 'be', 'night', 'or', 'day', '.', 'And', 'dark', 'thing', 'silent', 'crept', 'beneath', '.']\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "lemmas = [wnl.lemmatize(t) for t in tokens]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "100c6ad5-a5e6-4f7e-8fd5-b61d170999a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nA. The NLTK library has very strong functionalty in order to learn and experiment with the basics of NLP. There is access to a vast amount of example texts that already have\\n   many built in convenience functions. There are also a vast amount of built in implementation of common NLP algorithms such as lemmatizing and stemming.\\n\\nB. The code quality of the NLTK library is also very nice. The API is easily readable and understandable just by looking at the code itself. Each code has comments that make it\\n   clear what the function output and input is, as well as how it works. The API is also design in a way where it builds on top of each other and practices strong OOP concepts.\\n   The written documentation itself is also very easy to read and understand. It also provides numerous code examples that make it easy to read and immediately start coding\\n   \\nC. I may use NLTK for future projects in anything that relates to NLP or parsing and understanding text-based data.\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "A. The NLTK library has very strong functionalty in order to learn and experiment with the basics of NLP. There is access to a vast amount of example texts that already have\n",
    "   many built in convenience functions. There are also a vast amount of built in implementation of common NLP algorithms such as lemmatizing and stemming.\n",
    "\n",
    "B. The code quality of the NLTK library is also very nice. The API is easily readable and understandable just by looking at the code itself. Each code has comments that make it\n",
    "   clear what the function output and input is, as well as how it works. The API is also design in a way where it builds on top of each other and practices strong OOP concepts.\n",
    "   The written documentation itself is also very easy to read and understand. It also provides numerous code examples that make it easy to read and immediately start coding\n",
    "   \n",
    "C. I may use NLTK for future projects in anything that relates to NLP or parsing and understanding text-based data.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
