{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f1f501-91b1-4a59-b6b4-edd24d49685f",
   "metadata": {},
   "source": [
    "Wordnet is a large lexical database of semantic relationships between words. Wordnet can be used to assign these relationships between different words. The synonyms can then be grouped into synets with short definitions and usage examples. Wordnet works very similarly to a dictionary or thesaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01766e28-50cd-4d2a-8584-237f6d50d2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# library imports\n",
    "import nltk\n",
    "import math\n",
    "from nltk.book import text4\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bdfbfa-9378-451c-a4b1-465f57e1b127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motorcycle.n.01'), Synset('bicycle.n.01'), Synset('bicycle.v.01')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose a noun\n",
    "noun = \"bike\"\n",
    "#get its synsets\n",
    "synsets = wn.synsets(noun)\n",
    "#print the synsets\n",
    "synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f053c4a6-761b-4719-8bfd-6912ebfabcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a motor vehicle with two wheels and a strong frame\n",
      "[]\n",
      "[Lemma('motorcycle.n.01.motorcycle'), Lemma('motorcycle.n.01.bike')]\n"
     ]
    }
   ],
   "source": [
    "#choose motorcycle from the list of possible synsets\n",
    "motorcycle = synsets[0]\n",
    "\n",
    "#print its definition, its examples, and possible lemmas\n",
    "print(motorcycle.definition())\n",
    "print(motorcycle.examples())\n",
    "print(motorcycle.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cc9737-6c30-4e8f-94ae-3a06e268379a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motor_vehicle.n.01'),\n",
       " Synset('self-propelled_vehicle.n.01'),\n",
       " Synset('wheeled_vehicle.n.01'),\n",
       " Synset('container.n.01'),\n",
       " Synset('vehicle.n.01'),\n",
       " Synset('instrumentality.n.03'),\n",
       " Synset('conveyance.n.03'),\n",
       " Synset('artifact.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "#traverse and print the WordNet hierarchy tree\n",
    "hyper = lambda s: s.hypernyms()\n",
    "list(motorcycle.closure(hyper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ade3a6-37fb-4120-9862-65dd67fd8fef",
   "metadata": {},
   "source": [
    "Nouns seem to be classified by their usage, class as an object, then their relation to the rest of the physical world. For example, a motorbike is seen as motor vehicle at its highest level and then slowly describes as self-propelled or wheeled vehicle. Final it ends with synsets that simple refer to it as a physical object, then an entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2961cf82-ca28-44ea-8a9b-35dbdb8f6dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('motor_vehicle.n.01')]\n",
      "[Synset('minibike.n.01'), Synset('trail_bike.n.01')]\n",
      "[Synset('kick_starter.n.01'), Synset('kickstand.n.01'), Synset('mudguard.n.01')]\n",
      "[]\n",
      "[[], []]\n"
     ]
    }
   ],
   "source": [
    "#print motorcycle hypernyms\n",
    "print(motorcycle.hypernyms())\n",
    "#print motorcycle hyponyms\n",
    "print(motorcycle.hyponyms())\n",
    "#print motorcycle meronyms\n",
    "print(motorcycle.part_meronyms())\n",
    "#print motorcycle holonyms\n",
    "print(motorcycle.part_holonyms())\n",
    "#print all motorcycle lemma antonyms\n",
    "print([lemma.antonyms() for lemma in motorcycle.lemmas()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ab31bd-678d-44c3-9674-6595f80e6e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('run.n.01'),\n",
       " Synset('test.n.05'),\n",
       " Synset('footrace.n.01'),\n",
       " Synset('streak.n.01'),\n",
       " Synset('run.n.05'),\n",
       " Synset('run.n.06'),\n",
       " Synset('run.n.07'),\n",
       " Synset('run.n.08'),\n",
       " Synset('run.n.09'),\n",
       " Synset('run.n.10'),\n",
       " Synset('rivulet.n.01'),\n",
       " Synset('political_campaign.n.01'),\n",
       " Synset('run.n.13'),\n",
       " Synset('discharge.n.06'),\n",
       " Synset('run.n.15'),\n",
       " Synset('run.n.16'),\n",
       " Synset('run.v.01'),\n",
       " Synset('scat.v.01'),\n",
       " Synset('run.v.03'),\n",
       " Synset('operate.v.01'),\n",
       " Synset('run.v.05'),\n",
       " Synset('run.v.06'),\n",
       " Synset('function.v.01'),\n",
       " Synset('range.v.01'),\n",
       " Synset('campaign.v.01'),\n",
       " Synset('play.v.18'),\n",
       " Synset('run.v.11'),\n",
       " Synset('tend.v.01'),\n",
       " Synset('run.v.13'),\n",
       " Synset('run.v.14'),\n",
       " Synset('run.v.15'),\n",
       " Synset('run.v.16'),\n",
       " Synset('prevail.v.03'),\n",
       " Synset('run.v.18'),\n",
       " Synset('run.v.19'),\n",
       " Synset('carry.v.15'),\n",
       " Synset('run.v.21'),\n",
       " Synset('guide.v.05'),\n",
       " Synset('run.v.23'),\n",
       " Synset('run.v.24'),\n",
       " Synset('run.v.25'),\n",
       " Synset('run.v.26'),\n",
       " Synset('run.v.27'),\n",
       " Synset('run.v.28'),\n",
       " Synset('run.v.29'),\n",
       " Synset('run.v.30'),\n",
       " Synset('run.v.31'),\n",
       " Synset('run.v.32'),\n",
       " Synset('run.v.33'),\n",
       " Synset('run.v.34'),\n",
       " Synset('ply.v.03'),\n",
       " Synset('hunt.v.01'),\n",
       " Synset('race.v.02'),\n",
       " Synset('move.v.13'),\n",
       " Synset('melt.v.01'),\n",
       " Synset('ladder.v.01'),\n",
       " Synset('run.v.41')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose a verb\n",
    "verb = \"run\"\n",
    "#get all synsets of verb\n",
    "synsets = wn.synsets(verb)\n",
    "#print the verb synsets\n",
    "synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221fea00-b0e5-4785-967e-d4c4f99a563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce or cause to be reduced from a solid to a liquid state, usually by heating\n",
      "['melt butter', 'melt down gold', 'The wax melted in the sun']\n",
      "[Lemma('melt.v.01.melt'), Lemma('melt.v.01.run'), Lemma('melt.v.01.melt_down')]\n"
     ]
    }
   ],
   "source": [
    "#choose the verb melt from possible list of synsets\n",
    "melt = synsets[-3]\n",
    "\n",
    "#print melt definitions, examples, and lemmas\n",
    "print(melt.definition())\n",
    "print(melt.examples())\n",
    "print(melt.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2df2d3c1-21c9-4562-bff6-ab9063d51672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dissolve.v.02'),\n",
       " Synset('change_integrity.v.01'),\n",
       " Synset('change.v.02')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traverse and print the melt hiearchy tree\n",
    "list(melt.closure(hyper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08677bf4-198e-4067-82fa-1330f7e71051",
   "metadata": {},
   "source": [
    "Verbs seem to be organized starting from what specific change they could have on the world to a more general term on how they can effect the world. In this example, melt is specified as a verb that can be dissolving something such as snow. Then it becomes more broad, in that it changes the integrity of an existing object, and then finally that it introduces some type of change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5389a874-40a0-4c15-ac2e-d9b1c006d687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('run.v.01'),\n",
       " Synset('scat.v.01'),\n",
       " Synset('run.v.03'),\n",
       " Synset('operate.v.01'),\n",
       " Synset('run.v.05'),\n",
       " Synset('run.v.06'),\n",
       " Synset('function.v.01'),\n",
       " Synset('range.v.01'),\n",
       " Synset('campaign.v.01'),\n",
       " Synset('play.v.18'),\n",
       " Synset('run.v.11'),\n",
       " Synset('tend.v.01'),\n",
       " Synset('run.v.13'),\n",
       " Synset('run.v.14'),\n",
       " Synset('run.v.15'),\n",
       " Synset('run.v.16'),\n",
       " Synset('prevail.v.03'),\n",
       " Synset('run.v.18'),\n",
       " Synset('run.v.19'),\n",
       " Synset('carry.v.15'),\n",
       " Synset('run.v.21'),\n",
       " Synset('guide.v.05'),\n",
       " Synset('run.v.23'),\n",
       " Synset('run.v.24'),\n",
       " Synset('run.v.25'),\n",
       " Synset('run.v.26'),\n",
       " Synset('run.v.27'),\n",
       " Synset('run.v.28'),\n",
       " Synset('run.v.29'),\n",
       " Synset('run.v.30'),\n",
       " Synset('run.v.31'),\n",
       " Synset('run.v.32'),\n",
       " Synset('run.v.33'),\n",
       " Synset('run.v.34'),\n",
       " Synset('ply.v.03'),\n",
       " Synset('hunt.v.01'),\n",
       " Synset('race.v.02'),\n",
       " Synset('move.v.13'),\n",
       " Synset('melt.v.01'),\n",
       " Synset('ladder.v.01'),\n",
       " Synset('run.v.41')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose a morphy object for the verb \"run\"\n",
    "m = wn.morphy(\"run\")\n",
    "#get similar words that are all words\n",
    "similar_words = wn.synsets(m, wn.VERB)\n",
    "#display the similar words\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc30ba2-6712-4910-aa6d-401c4ce6e988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "#wu path similarity for \"hunt\" and \"move\"\n",
    "hunt = wn.synset(\"hunt.v.01\")\n",
    "move = wn.synset(\"move.v.13\")\n",
    "\n",
    "print(wn.path_similarity(hunt, move))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46df45cd-59b5-4c62-a727-e78d25b64975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('search.n.01')\n"
     ]
    }
   ],
   "source": [
    "#lesk algorithm for \"hunt\"\n",
    "raw_text = \"I went to the forest to hunt for deer .\"\n",
    "sent = raw_text.split()\n",
    "\n",
    "print(lesk(sent, \"hunt\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6623c-26b0-410c-917c-4cbdf279c2b5",
   "metadata": {},
   "source": [
    "The Wu-Path similarity algorithm can be used to measure the similiarty between two words. The algorithm seems to work well since it ranked hunt and move with a similarity of 0.16%. This makes sense since each word has a very different connotation. Hunting refers to chasing toward something, while move simply refers to having some type of motion, with no goal in mind. The Lesk algorithm also works quite well in detecting the intension of the target verb. In my sentence I used hunt to refer to the sporting activity of hunting game. The leask algorithm provided the synset of \"search\". This is accurate since hunting in this context is the action of searching for a deer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8d6a2-e186-45c4-be22-800bd8f6c0b2",
   "metadata": {},
   "source": [
    "SentiNet is an extension of WordNet that allows you to preform sentiment analysis easily. It works by assigning one of three possible sentiments to each synset: positivity, negativity, or objectivity. NLTK provides an easy access to the SentiNet algorithm that can be used in several ways. For example, a naive sentiment anaylsis would consist of iterating over all synsets, getting the sentiment score, and count how many are positive versus negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdda6083-aa24-43f9-8175-d95d016b3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<atrocious.s.02: PosScore=0.0 NegScore=0.875>\n",
      "<awful.s.02: PosScore=0.0 NegScore=0.625>\n",
      "<nasty.a.01: PosScore=0.0 NegScore=0.875>\n",
      "<awed.s.01: PosScore=0.5 NegScore=0.5>\n",
      "<frightful.s.02: PosScore=0.125 NegScore=0.25>\n",
      "<amazing.s.02: PosScore=0.875 NegScore=0.125>\n",
      "<terribly.r.01: PosScore=0.25 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "#get list of SentiNet synonyms for \"awful\"\n",
    "senti_list = list(swn.senti_synsets('awful'))\n",
    "#print the polarity info for each synonym\n",
    "for item in senti_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d82c8664-03f1-4d97-bd7c-be8115fb57c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chair.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<be.v.01: PosScore=0.25 NegScore=0.125>\n",
      "<very.s.01: PosScore=0.5 NegScore=0.0>\n",
      "<uncomfortable.a.01: PosScore=0.0 NegScore=0.75>\n"
     ]
    }
   ],
   "source": [
    "#example emotional sentence\n",
    "sent = \"This chair is very uncomfortable\"\n",
    "#split sentence into list of indivivual words\n",
    "tokens = sent.split()\n",
    "\n",
    "#for each token, print the polarity info\n",
    "for token in tokens:\n",
    "    syn_list = list(swn.senti_synsets(token))\n",
    "    if syn_list:\n",
    "        print(syn_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac24c3-82df-4536-b6ce-b560da5ed373",
   "metadata": {},
   "source": [
    "The SentiNet is used to derive the sentiment score of each word. By looking at my example, I notice that it assigns to polarity to objects that hold no other context such as chair. It assigns a failr even polarity to verbs that only act to describe a state of being. However, words that are generally used with a heavy conotation have a strong polarity skew. In my example, \"uncomfortable\" is usually only used to describe something in a negative way, so it has a strong negative polarity score and no positive polarity score. This data can be very useful in NLP contexts, since it allows us generalize a base understanding of any input speech. We can programming learning negative or positive text. This might be useful in applications like learning from customer feedback. We can quickly see if a piece of provided feedback and is negative or positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83e8f4-9edd-4ad7-81a5-c72a3ad73967",
   "metadata": {},
   "source": [
    "A collocation is a relationship between two words that often occurs in normal human speech of text. A collocation may be formed if we notice that two or more words tend to occur together with a frequency greater than chance would suggest. This suggests that the two words are often used together when refered to. Another indicator that two words may be a collocation is that you cannot substitute synonyms. For example, \"wild west\" does not mean the same as \"feral west\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8ac7a7-d7e0-4aea-a43c-92fdf3a40c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "#display all collocations for text4\n",
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e553185d-74a8-4e43-b41e-81f094e7914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(fellow citizens) =  0.013665835411471322\n",
      "p(fellow) =  0.013665835411471322\n",
      "p(citizens) =  0.026932668329177057\n",
      "pmi =  5.214499019178814\n"
     ]
    }
   ],
   "source": [
    "#calculate and print pmi probabilities for the possible collocations \"fellow citizens\"\n",
    "text = ' '.join(text4.tokens)\n",
    "\n",
    "vocab = len(set(text4))\n",
    "hg = text.count('fellow')/vocab\n",
    "print(\"p(fellow citizens) = \",hg )\n",
    "h = text.count('fellow')/vocab\n",
    "print(\"p(fellow) = \", h)\n",
    "g = text.count('citizens')/vocab\n",
    "print('p(citizens) = ', g)\n",
    "pmi = math.log2(hg / (h * g))\n",
    "print('pmi = ', pmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0a74f-10da-4692-9a96-89a59ca86838",
   "metadata": {},
   "source": [
    "PMI works by finding the probability of words x and y occurring next to each other, and dividing this by the probability of x multiplied by the probability of y. A pmi values of 0 would indicate that the words are independent. If the pmi is negative, then there is proof that x and y are not a collocation. Finally a positive pmi could be evidence that there is a strong collocation relationship. For the example that I used above, we got a pmi value of 5. This is a large positive value, so we can conclude that is probably strong evidence that \"fellow citizens\" is a collocation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
